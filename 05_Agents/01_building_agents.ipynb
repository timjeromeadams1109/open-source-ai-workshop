{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Building AI Agents\n",
    "\n",
    "In this lab, you'll build **AI agents** that can use tools, make decisions, and accomplish complex tasks autonomously.\n",
    "\n",
    "## What is an AI Agent?\n",
    "An AI agent is an LLM that can:\n",
    "1. **Reason** about how to accomplish a goal\n",
    "2. **Use tools** to interact with the world\n",
    "3. **Iterate** based on results\n",
    "4. **Complete tasks** autonomously\n",
    "\n",
    "## What You'll Learn\n",
    "- Building agents with LangChain\n",
    "- Creating custom tools\n",
    "- ReAct agents (Reasoning + Acting)\n",
    "- Multi-step task execution\n",
    "- Building a customer service agent\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install langchain langchain-community\n",
    "ollama pull llama3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community ollama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool, tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Test it\n",
    "response = llm.invoke(\"Say 'Hello, Agent!'\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Tools\n",
    "\n",
    "Tools are functions that agents can call to interact with the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple tool using decorator\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    Input should be a valid Python math expression like '2 + 2' or '10 * 5'.\"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of math expressions\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when asked about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search the company knowledge base for information.\n",
    "    Use this to look up product information, policies, or FAQs.\"\"\"\n",
    "    # Simulated knowledge base\n",
    "    knowledge = {\n",
    "        \"return policy\": \"Items can be returned within 30 days with receipt for full refund.\",\n",
    "        \"shipping\": \"Free shipping on orders over $50. Standard delivery takes 3-5 business days.\",\n",
    "        \"warranty\": \"All products come with a 1-year manufacturer warranty.\",\n",
    "        \"hours\": \"Customer service is available Monday-Friday, 9 AM - 5 PM EST.\",\n",
    "        \"contact\": \"Email: support@example.com, Phone: 1-800-EXAMPLE\"\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    for key, value in knowledge.items():\n",
    "        if key in query_lower:\n",
    "            return value\n",
    "    return \"I couldn't find specific information about that. Please contact support for help.\"\n",
    "\n",
    "# List our tools\n",
    "tools = [calculator, get_current_time, search_knowledge_base]\n",
    "print(\"Available tools:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a ReAct Agent\n",
    "\n",
    "ReAct (Reasoning + Acting) agents think step-by-step and use tools to solve problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt template\n",
    "react_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(llm, tools, react_prompt)\n",
    "\n",
    "# Create the executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,  # Show reasoning\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(\"Agent ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple question\n",
    "result = agent_executor.invoke({\"input\": \"What is 25 * 17?\"})\n",
    "print(\"\\nFinal Answer:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with knowledge base\n",
    "result = agent_executor.invoke({\"input\": \"What is your return policy?\"})\n",
    "print(\"\\nFinal Answer:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step question\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"If I buy 3 items at $29.99 each, what's my total? And do I get free shipping?\"\n",
    "})\n",
    "print(\"\\nFinal Answer:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Customer Service Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated tools for customer service\n",
    "\n",
    "# Simulated database\n",
    "orders_db = {\n",
    "    \"ORD-001\": {\"status\": \"shipped\", \"tracking\": \"1Z999AA10123456784\", \"items\": [\"Widget A\", \"Widget B\"], \"total\": 59.99},\n",
    "    \"ORD-002\": {\"status\": \"processing\", \"tracking\": None, \"items\": [\"Gadget X\"], \"total\": 129.99},\n",
    "    \"ORD-003\": {\"status\": \"delivered\", \"tracking\": \"1Z999AA10123456785\", \"items\": [\"Super Gizmo\"], \"total\": 249.99},\n",
    "}\n",
    "\n",
    "customers_db = {\n",
    "    \"CUST-100\": {\"name\": \"Alice Smith\", \"email\": \"alice@example.com\", \"orders\": [\"ORD-001\", \"ORD-003\"]},\n",
    "    \"CUST-101\": {\"name\": \"Bob Jones\", \"email\": \"bob@example.com\", \"orders\": [\"ORD-002\"]},\n",
    "}\n",
    "\n",
    "@tool\n",
    "def lookup_order(order_id: str) -> str:\n",
    "    \"\"\"Look up order details by order ID. Use this when customer asks about their order status.\n",
    "    Input should be an order ID like 'ORD-001'.\"\"\"\n",
    "    order = orders_db.get(order_id.upper())\n",
    "    if order:\n",
    "        return json.dumps(order, indent=2)\n",
    "    return f\"Order {order_id} not found.\"\n",
    "\n",
    "@tool\n",
    "def lookup_customer(customer_id: str) -> str:\n",
    "    \"\"\"Look up customer information by customer ID.\n",
    "    Input should be a customer ID like 'CUST-100'.\"\"\"\n",
    "    customer = customers_db.get(customer_id.upper())\n",
    "    if customer:\n",
    "        return json.dumps(customer, indent=2)\n",
    "    return f\"Customer {customer_id} not found.\"\n",
    "\n",
    "@tool\n",
    "def initiate_return(order_id: str) -> str:\n",
    "    \"\"\"Initiate a return for an order. Use when customer wants to return an item.\n",
    "    Input should be the order ID to return.\"\"\"\n",
    "    order = orders_db.get(order_id.upper())\n",
    "    if order:\n",
    "        if order[\"status\"] == \"delivered\":\n",
    "            return f\"Return initiated for {order_id}. Return label will be emailed within 24 hours.\"\n",
    "        else:\n",
    "            return f\"Cannot initiate return - order {order_id} status is '{order['status']}'. Only delivered orders can be returned.\"\n",
    "    return f\"Order {order_id} not found.\"\n",
    "\n",
    "@tool\n",
    "def escalate_to_human(reason: str) -> str:\n",
    "    \"\"\"Escalate the conversation to a human agent. Use this when the customer's issue cannot be resolved automatically.\n",
    "    Input should be a brief description of why escalation is needed.\"\"\"\n",
    "    return f\"Escalating to human agent. Reason: {reason}. A representative will contact you within 2 hours.\"\n",
    "\n",
    "# Customer service tools\n",
    "cs_tools = [lookup_order, lookup_customer, initiate_return, escalate_to_human, search_knowledge_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer service agent prompt\n",
    "cs_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful customer service agent for TechCorp. Be friendly, professional, and helpful.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the customer's question or request\n",
    "Thought: think about how to help the customer\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I can now respond to the customer\n",
    "Final Answer: your helpful response to the customer\n",
    "\n",
    "Remember:\n",
    "- Always be polite and helpful\n",
    "- Look up information before making claims\n",
    "- If you can't help, offer to escalate\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# Create customer service agent\n",
    "cs_agent = create_react_agent(llm, cs_tools, cs_prompt)\n",
    "cs_executor = AgentExecutor(\n",
    "    agent=cs_agent,\n",
    "    tools=cs_tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "print(\"Customer service agent ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test customer service scenarios\n",
    "\n",
    "# Scenario 1: Order status\n",
    "print(\"=\" * 50)\n",
    "print(\"Scenario 1: Order Status Inquiry\")\n",
    "print(\"=\" * 50)\n",
    "result = cs_executor.invoke({\"input\": \"Hi, I'd like to check on my order ORD-001\"})\n",
    "print(\"\\nAgent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Return request\n",
    "print(\"=\" * 50)\n",
    "print(\"Scenario 2: Return Request\")\n",
    "print(\"=\" * 50)\n",
    "result = cs_executor.invoke({\"input\": \"I want to return order ORD-003, it's not what I expected\"})\n",
    "print(\"\\nAgent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Policy question\n",
    "print(\"=\" * 50)\n",
    "print(\"Scenario 3: Policy Question\")\n",
    "print(\"=\" * 50)\n",
    "result = cs_executor.invoke({\"input\": \"Do you offer free shipping? And what's the warranty on your products?\"})\n",
    "print(\"\\nAgent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Create memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Modified prompt with memory\n",
    "memory_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant with access to tools.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "Tools available:\n",
    "{tools}\n",
    "\n",
    "Format:\n",
    "Question: the input question\n",
    "Thought: think about what to do\n",
    "Action: one of [{tool_names}]\n",
    "Action Input: the input\n",
    "Observation: the result\n",
    "Thought: I know the answer\n",
    "Final Answer: the answer\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "# This is simplified - full memory integration requires more setup\n",
    "print(\"Memory-enabled agent concept demonstrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Simple Agent Without LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also build simple agents with just Ollama\n",
    "import ollama\n",
    "\n",
    "def simple_agent(user_input: str, max_steps: int = 5) -> str:\n",
    "    \"\"\"A simple agent that can use tools.\"\"\"\n",
    "    \n",
    "    # Define available tools\n",
    "    tool_definitions = \"\"\"\n",
    "    Available tools:\n",
    "    1. calculator(expression) - Evaluates math expressions\n",
    "    2. search(query) - Searches the knowledge base\n",
    "    3. done(answer) - Returns final answer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simple tool implementations\n",
    "    def run_tool(tool_name: str, tool_input: str) -> str:\n",
    "        if tool_name == \"calculator\":\n",
    "            try:\n",
    "                return str(eval(tool_input, {\"__builtins__\": {}}, {}))\n",
    "            except:\n",
    "                return \"Error evaluating expression\"\n",
    "        elif tool_name == \"search\":\n",
    "            kb = {\"shipping\": \"Free over $50\", \"returns\": \"30 day policy\"}\n",
    "            for k, v in kb.items():\n",
    "                if k in tool_input.lower():\n",
    "                    return v\n",
    "            return \"Not found\"\n",
    "        return \"Unknown tool\"\n",
    "    \n",
    "    context = f\"User: {user_input}\\n\"\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        prompt = f\"\"\"\n",
    "        {tool_definitions}\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        What tool should be used next? Respond with:\n",
    "        TOOL: tool_name\n",
    "        INPUT: tool_input\n",
    "        \n",
    "        Or if you have the answer:\n",
    "        TOOL: done\n",
    "        INPUT: your final answer\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model='llama3.2',\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )['message']['content']\n",
    "        \n",
    "        # Parse response\n",
    "        lines = response.strip().split('\\n')\n",
    "        tool_name = None\n",
    "        tool_input = None\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith('TOOL:'):\n",
    "                tool_name = line.replace('TOOL:', '').strip().lower()\n",
    "            elif line.startswith('INPUT:'):\n",
    "                tool_input = line.replace('INPUT:', '').strip()\n",
    "        \n",
    "        if tool_name == 'done':\n",
    "            return tool_input\n",
    "        \n",
    "        if tool_name and tool_input:\n",
    "            result = run_tool(tool_name, tool_input)\n",
    "            context += f\"\\nUsed {tool_name}({tool_input}) -> {result}\"\n",
    "    \n",
    "    return \"Could not complete task\"\n",
    "\n",
    "# Test simple agent\n",
    "print(\"Simple Agent Test:\")\n",
    "result = simple_agent(\"What is 15 * 23?\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "- Create custom tools for agents\n",
    "- Build ReAct agents with LangChain\n",
    "- Handle multi-step reasoning\n",
    "- Create a customer service agent\n",
    "- Implement simple agents from scratch\n",
    "\n",
    "**Key takeaways:**\n",
    "- Agents combine LLMs with tools for autonomous task completion\n",
    "- ReAct pattern: Reason → Act → Observe → Repeat\n",
    "- Good tool descriptions are crucial for agent success\n",
    "- Everything runs locally with Ollama!\n",
    "\n",
    "**Ideas for extending:**\n",
    "- Add more tools (web search, file operations, APIs)\n",
    "- Build a coding assistant agent\n",
    "- Create multi-agent systems\n",
    "- Add persistent memory\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the Open Source AI Workshop. You now have the skills to:\n",
    "- Generate text with local LLMs\n",
    "- Build RAG systems\n",
    "- Fine-tune models\n",
    "- Generate and analyze images\n",
    "- Create AI agents\n",
    "\n",
    "All running locally, completely free!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
